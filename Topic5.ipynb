{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "V7d4nJ3TKcSf"
   },
   "outputs": [],
   "source": [
    "Assignment-5 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Agents are an emerging field thats use reflection, tools, planning, and multi agent collaboration\n",
    "\n",
    "In this assignment, we will build a research agent. We will use serverless LLM endpoints. To get started, you create an account with Together AI or Anthropic. They should provide you with a few dollars worth of credits that should be enough to complete the assignment. You are free to choose any other provider such as OpenAI, Mistral, Fireworks, or Groq. I encourage you to play around with different models to get a feel for how they work. For this assignment, the API usage cost should be around a couple dollars. Depending on the model you choose and how many attempts you use, it may be a couple cents. For OpenAI, Anthropic, and Mistral, double check what model you are using. The flagship models are significantly more expensive than the smaller models (pricing between models varies by 50x). For the purposes of this assignment, it is sufficient to use the smallest/cheapest models.\n",
    "\n",
    "TogetherAI, Fireworks, and Groq run open source models. For these, it’s better to run the mid-large tier models. Mixtral is a good place to start. It’s good to play around with different models.\n",
    "\n",
    "Many providers are able to use OpenAI's client library, but some do not (like Anthropic). Use whatever makes sense.\n",
    "\n",
    "You can run this on Colab with a CPU, or locally and submit the Jupyter notebook as your submission. Since we are using third party providers for the LLMs, we will not load the model locally. If you run on Colab, take special care to not leak your API key. Here’s an example of how to properly use secrets in Colab.\n",
    "\n",
    "Research Agent\n",
    "Build an LLM-based research agent that can take a research topic, find relevant information, and generate a short summary (~1 paragraph) on the given topic.\n",
    "\n",
    "Tools to Implement (20 points, 4 points each):\n",
    "1. Topic Breakdown Tool: Create a tool that takes a broad research topic and breaks it down into smaller, more focused subtopics or subqueries. You can use an LLM to generate these subtopics based on the main topic.\n",
    "\n",
    "2. Query Expansion Tool: Develop a tool to expand the subqueries generated by the Topic Breakdown Tool. The tool should generate related keywords, synonyms, and phrases to enhance the search results.\n",
    "\n",
    "3. Search Tool: Create a wrapper around the You API or Brave Search API, Serper.dev. Please note that the free tier is 1000 queries/month. Consider creating a mock while developing, and switch to actually call the You API once the agent is more stable. Additionally, consider caching the search results.\n",
    "\n",
    "4. Critique Tool: Create a tool that critiques the summary, and offers suggestions of how to improve and potentially other relevant topics to search for. \n",
    "\n",
    "5. Summarizer Tool (optional): Create a tool that takes some input and summarizes its content using an LLM.\n",
    "\n",
    "Workflow (30 points)\n",
    "Implement an agent workflow that uses all of these tools. In the agent workflow, the agent should be provided with all the tools and it should decide which tool to use. For the individual tool implementations, if you use a call to an LLM you do not need to provide any tools. \n",
    "\n",
    "Sample Agent Workflow:\n",
    "1. The agent receives a research topic from the user.\n",
    "2. It uses the Topic Breakdown Tool to generate subtopics or subqueries.\n",
    "3. The Query Expansion Tool expands the subqueries with related keywords and phrases.\n",
    "4. The Search Tool uses the expanded queries and subqueries to gather relevant information from various sources.\n",
    "5. The agent generates the summary incorporating the search results. (optional)\n",
    "6. The agent critiques the summary, and improves the results. (optional)\n",
    "7. The agent presents the final summary to the user.\n",
    "\n",
    "The sample workflow is the minimum implementation requirement. Feel free to add more tools, add loops in the workflow, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "HkMW5okDLssa",
    "outputId": "be2e09ea-1457-4765-d579-10cbfec5f29c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting together\n",
      "  Downloading together-1.3.5-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.9.3 in /usr/local/lib/python3.10/dist-packages (from together) (3.11.10)\n",
      "Requirement already satisfied: click<9.0.0,>=8.1.7 in /usr/local/lib/python3.10/dist-packages (from together) (8.1.7)\n",
      "Requirement already satisfied: eval-type-backport<0.3.0,>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from together) (0.2.0)\n",
      "Requirement already satisfied: filelock<4.0.0,>=3.13.1 in /usr/local/lib/python3.10/dist-packages (from together) (3.16.1)\n",
      "Requirement already satisfied: numpy>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from together) (1.26.4)\n",
      "Collecting pillow<11.0.0,>=10.3.0 (from together)\n",
      "  Downloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: pyarrow>=10.0.1 in /usr/local/lib/python3.10/dist-packages (from together) (17.0.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.6.3 in /usr/local/lib/python3.10/dist-packages (from together) (2.10.3)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from together) (2.32.3)\n",
      "Requirement already satisfied: rich<14.0.0,>=13.8.1 in /usr/local/lib/python3.10/dist-packages (from together) (13.9.4)\n",
      "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from together) (0.9.0)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.66.2 in /usr/local/lib/python3.10/dist-packages (from together) (4.66.6)\n",
      "Collecting typer<0.14,>=0.9 (from together)\n",
      "  Downloading typer-0.13.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (2.4.4)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.3.1)\n",
      "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (4.0.3)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (0.2.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.9.3->together) (1.18.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (2.27.1)\n",
      "Requirement already satisfied: typing-extensions>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.6.3->together) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->together) (2024.8.30)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=13.8.1->together) (2.18.0)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<0.14,>=0.9->together) (1.5.4)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=13.8.1->together) (0.1.2)\n",
      "Downloading together-1.3.5-py3-none-any.whl (70 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.3/70.3 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pillow-10.4.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.13.1-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/44.7 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: pillow, typer, together\n",
      "  Attempting uninstall: pillow\n",
      "    Found existing installation: pillow 11.0.0\n",
      "    Uninstalling pillow-11.0.0:\n",
      "      Successfully uninstalled pillow-11.0.0\n",
      "  Attempting uninstall: typer\n",
      "    Found existing installation: typer 0.15.1\n",
      "    Uninstalling typer-0.15.1:\n",
      "      Successfully uninstalled typer-0.15.1\n",
      "Successfully installed pillow-10.4.0 together-1.3.5 typer-0.13.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.colab-display-data+json": {
       "id": "07720da0f9014ab0b2fb56cb64c4b0bb",
       "pip_warning": {
        "packages": [
         "PIL"
        ]
       }
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pip install --upgrade together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "beJzDHDZLwOM",
    "outputId": "b81ee074-89ac-4f0a-bba7-17cd6fa2812d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.54.5)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.8.2)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.10.3)\n",
      "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.27.1)\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XM0GmVc1L55f",
    "outputId": "470431dc-e5dc-4f4e-f440-5aa243622393"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: openai\n",
      "Version: 1.54.5\n",
      "Summary: The official Python library for the openai API\n",
      "Home-page: https://github.com/openai/openai-python\n",
      "Author: \n",
      "Author-email: OpenAI <support@openai.com>\n",
      "License: Apache-2.0\n",
      "Location: /usr/local/lib/python3.10/dist-packages\n",
      "Requires: anyio, distro, httpx, jiter, pydantic, sniffio, tqdm, typing-extensions\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "XUaJpVQyL-mC"
   },
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "La5fVR7gMCHc"
   },
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "my_secret_key = userdata.get('api_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wxurhz1lMIs5"
   },
   "outputs": [],
   "source": [
    "import together\n",
    "client = together.Client(api_key=my_secret_key,base_url='https://api.together.xyz/v1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nEDvh8l6MNUO"
   },
   "outputs": [],
   "source": [
    "model_name = \"mistralai/Mixtral-8x7B-Instruct-v0.1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Q15EDoxSMPvw"
   },
   "outputs": [],
   "source": [
    "def topic_breakdown_tool(research_topic):\n",
    "      chat_completion = client.chat.completions.create(\n",
    "        messages=[\n",
    "          {\n",
    "            \"role\": \"system\",\n",
    "            \"content\": \"You are an AI research assistant.\",\n",
    "          },\n",
    "          {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": f\"Generate 4 subQUERIES based on the research topic: {research_topic}.\",\n",
    "          }\n",
    "        ],\n",
    "        model=model_name,\n",
    "        temperature=0.9,\n",
    "        max_tokens=256,\n",
    "        top_k=40\n",
    "      )\n",
    "      subqueries=chat_completion.choices[0].message.content\n",
    "\n",
    "      return subqueries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "-XbX6PqmMSNG"
   },
   "outputs": [],
   "source": [
    "def query_expansion_tool(subqueries):\n",
    "    conversation = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI research assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Generate 4 keywords, synonyms, and phrases for each of the subqueries:{subqueries} and should follow the following format: {{'Subquery':Subquery,'Keywords':keywords,'Synonyms':Synonyms,'Phrases':phrases}}\"}\n",
    "    ]\n",
    "    # Request chat completions for generating keywords based on the conversation\n",
    "    chat_completion = client.chat.completions.create(\n",
    "        messages=conversation,\n",
    "        model=model_name,\n",
    "        temperature=0.9,\n",
    "        max_tokens=512,\n",
    "        top_k=40\n",
    "    )\n",
    "\n",
    "    # Extract keywords from the completion\n",
    "    expanded_queries = chat_completion.choices[0].message.content\n",
    "    return expanded_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Bemu4eiXNvas"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from cachetools import TTLCache\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Initialize a cache with a time-to-live (TTL) of 3600 seconds (1 hour)\n",
    "\n",
    "\n",
    "def search_tool(query):\n",
    "    headers = {\"X-API-Key\": my_secret_key}\n",
    "    params = {\"query\": query}\n",
    "    response= requests.get(\n",
    "        f\"https://api.ydc-index.io/search?query={query}\",\n",
    "        params=params,\n",
    "        headers=headers,\n",
    "    ).json()\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZXRrDaTTMUnh"
   },
   "outputs": [],
   "source": [
    "def summary_tool(search_result):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI research assistant.\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Provide Summary for the following search results generated:\\n\\n{search_result}.\"}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        max_tokens=500,\n",
    "        stop=None,\n",
    "        temperature=0.8,\n",
    "    )\n",
    "    summary = response.choices[0].message.content\n",
    "    return summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "nkzoZC-SNSeb"
   },
   "outputs": [],
   "source": [
    "def critique_tool(summary):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an AI research assistant acting as a critique\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Please critique the following summary:\\n\\n{summary}. Recognize flaws within the summary, offer constructive criticism, and pinpoint areas for improvement\"}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        max_tokens=500,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    critique = response.choices[0].message.content\n",
    "    return critique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oB7Lk7d8NUpt"
   },
   "outputs": [],
   "source": [
    "def final_summary_based_on_critique(summary, critique):\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": \"You are an Ai assistant conducting research\"},\n",
    "        {\"role\": \"user\", \"content\": f\"Enhance the provided summary: {summary} in accordance with the ensuing evaluation: {critique}.\"}\n",
    "    ]\n",
    "    response = client.chat.completions.create(\n",
    "        model=model_name,\n",
    "        messages=messages,\n",
    "        max_tokens=500,\n",
    "        stop=None,\n",
    "        temperature=0.7,\n",
    "    )\n",
    "    final_summary= response.choices[0].message.content\n",
    "    return final_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "s5sqIoYuNXEP"
   },
   "outputs": [],
   "source": [
    "def research_agent():\n",
    "\n",
    "  topic_of_research = input(\"Welcome! I am your research assistant, ready to help you discover relevant topics and provide valuable summaries. Please enter your research topic::\\n\\n\\nTopic Of Research:\")\n",
    "  print(\"\\n\\n 1. Topic Breakdown Tool :\")\n",
    "  subqueries = topic_breakdown_tool(topic_of_research)\n",
    "  print(f\"\\n {subqueries}\")\n",
    "\n",
    "  print(\"\\n\\n 2. Query Expansion Tool :\")\n",
    "  extended_subqueries = query_expansion_tool(subqueries)\n",
    "  print(f\"\\n {extended_subqueries}\")\n",
    "\n",
    "  print(\"\\n\\n 3. Search Tool : \")\n",
    "  search_results = search_tool(extended_subqueries)\n",
    "  print(f\"\\n {search_results}\")\n",
    "\n",
    "  print(\"\\n\\n 4. Summary Tool :\")\n",
    "  summary = summary_tool(search_results)\n",
    "  print(f\"\\n {summary}\")\n",
    "\n",
    "  print(\"\\n\\n 5. Critique Tool :\")\n",
    "  critic_results = critique_tool(summary)\n",
    "  print(f\"\\n {critic_results}\")\n",
    "\n",
    "  print(\"\\n\\n 6. Final Summary Generator based on summary and crtique:\")\n",
    "  final_summary = final_summary_based_on_critique(summary, critic_results)\n",
    "  print(f\"\\n {final_summary}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AW60_oV9NbDy",
    "outputId": "aac30c98-0e99-4785-e247-293044ecde25"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome! I am your research assistant, ready to help you discover relevant topics and provide valuable summaries. Please enter your research topic::\n",
      "\n",
      "\n",
      "Topic Of Research:IoT in LLM\n",
      "\n",
      "\n",
      " 1. Topic Breakdown Tool :\n",
      "\n",
      "  Sure, I can help with that. Here are four possible sub-queries related to the topic of \"IoT in LLM\" (I'm assuming you mean \"Low-Latency Machine-Type Communications\" by LLM):\n",
      "\n",
      "1. What are the key technical challenges in implementing IoT devices with LLM capabilities?\n",
      "2. How can LLM improve the reliability and efficiency of IoT networks, and what are some real-world use cases?\n",
      "3. What security risks do IoT devices with LLM capabilities introduce, and how can they be mitigated?\n",
      "4. How do the communication protocols used in IoT devices with LLM capabilities differ from those used in traditional IoT devices, and what are the benefits and drawbacks of each approach?\n",
      "\n",
      "\n",
      " 2. Query Expansion Tool :\n",
      "\n",
      "  1. What are the key technical challenges in implementing IoT devices with LLM capabilities?\n",
      "{'Subquery': 'technical challenges in implementing IoT devices with LLM capabilities',\n",
      "'Keywords': ['technical challenges', 'implementing', 'IoT devices', 'LLM capabilities'],\n",
      "'Synonyms': ['issues', 'obstacles', 'problems', 'difficulties', 'deploying', 'setting up'],\n",
      "'Phrases': ['challenges in developing IoT devices for LLM', 'difficulties in implementing LLM in IoT devices', 'issues in deploying IoT devices with LLM capabilities']}\n",
      "2. How can LLM improve the reliability and efficiency of IoT networks, and what are some real-world use cases?\n",
      "{'Subquery': 'LLM improving reliability and efficiency of IoT networks and real-world use cases',\n",
      "'Keywords': ['LLM', 'reliability', 'efficiency', 'IoT networks', 'use cases'],\n",
      "'Synonyms': ['enhancements', 'improvements', 'optimization', 'practical applications'],\n",
      "'Phrases': ['benefits of LLM for enhancing IoT network reliability and efficiency', 'practical uses of LLM in IoT networks', 'impact of LLM on IoT network performance and real-world scenarios']}\n",
      "3. What security risks do IoT devices with LLM capabilities introduce, and how can they be mitigated?\n",
      "{'Subquery': 'security risks and mitigation for IoT devices with LLM capabilities',\n",
      "'Keywords': ['security risks', 'IoT devices', 'LLM capabilities', 'mitigation'],\n",
      "'Synonyms': ['threats', 'vulnerabilities', 'protection', 'defense'],\n",
      "'Phrases': ['risks associated with LLM in IoT devices', 'strategies for mitigating security issues in LLM-enabled IoT', 'vulnerabilities in IoT devices with LLM capabilities and possible countermeasures']}\n",
      "4. How do the communication protocols used in IoT devices with LLM capabilities differ from those used in traditional IoT devices, and what are the benefits and drawbacks of each approach?\n",
      "{'Subquery': 'communication protocols in IoT devices with LLM\n",
      "\n",
      "\n",
      " 3. Search Tool : \n",
      "\n",
      " {'message': 'Forbidden'}\n",
      "\n",
      "\n",
      " 4. Summary Tool :\n",
      "\n",
      "  The search results contain a single message stating \"Forbidden,\" which suggests that access to the requested information or resources has been denied. This summary is brief due to the limited and uninformative nature of the search results.\n",
      "\n",
      "\n",
      " 5. Critique Tool :\n",
      "\n",
      "  The summary is indeed brief, but it could benefit from a more detailed analysis of the situation. Instead of simply stating that the search results contain the message \"Forbidden,\" the summary could explain why this message might appear. For instance, it could mention that this message often indicates an issue with permissions or access levels, or that it might be the result of a deliberate attempt to restrict access to certain resources.\n",
      "\n",
      "Furthermore, the summary could provide some suggestions for next steps. For example, it could recommend checking the user's permissions or contacting the system administrator for assistance.\n",
      "\n",
      "Overall, while the summary is factually accurate, it could be more informative and helpful by providing additional context and recommendations.\n",
      "\n",
      "\n",
      " 6. Final Summary Generator based on summary and crtique:\n",
      "\n",
      "  The search results returned a single message: \"Forbidden,\" indicating that access to the desired information or resources has been restricted. This response is often indicative of permission issues or deliberate restriction of access. To further investigate, consider examining the user's permissions settings or consulting with the system administrator for assistance. This summary aims to provide a more detailed understanding of the situation and suggest potential avenues for resolving the \"Forbidden\" message.\n"
     ]
    }
   ],
   "source": [
    "research_agent()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
